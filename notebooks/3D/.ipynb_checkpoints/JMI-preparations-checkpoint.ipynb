{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c01a175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a956a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_images_path = '/work/forkert_lab/erik/MACAW/cf_images'\n",
    "original_image_path = '/work/forkert_lab/erik/T1_cropped'\n",
    "output_path = '/work/forkert_lab/erik/JMI_paper_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9c06f",
   "metadata": {},
   "source": [
    "# Composition and reversibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0392f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_eid = 4517026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b21fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero differences\n",
    "axial_path_zero = '2_5Z_65_reverse'\n",
    "twofive_path_zero = '2_5YZ_65_reverse'\n",
    "pca3D_path_zero = 'PCA3D_15000_new_65_reverse'\n",
    "autoencoder_path_zero = 'macaw_AE3D_6000_65_reverse'\n",
    "vqvae_path_zero = 'macaw_vqvae8_50_nevecs_65_reverse'\n",
    "# Reversebility\n",
    "axial_path_10 =  '2_5Z_sex_0_reverse'\n",
    "twofive_path_10 =  '2_5YZ_sex_0_reverse'\n",
    "pca3D_path_10 =  'PCA3D_15000_new_sex_0_reverse'\n",
    "autoencoder_path_10 = 'macaw_AE3D_6000_sex_0_reverse'\n",
    "vqvae_path_10 = 'macaw_vqvae8_50_nevecs_sex_0_reverse'\n",
    "\n",
    "comp_rever_paths_all = [axial_path_zero,\n",
    "                       twofive_path_zero,\n",
    "                       pca3D_path_zero,\n",
    "                       autoencoder_path_zero,\n",
    "                       vqvae_path_zero,\n",
    "                       axial_path_10,\n",
    "                       twofive_path_10,\n",
    "                       pca3D_path_10,\n",
    "                       autoencoder_path_10,\n",
    "                       vqvae_path_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d25c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting original images\n",
    "original_image = nib.load(os.path.join(original_image_path, str(original_image_eid) + \".nii.gz\"))\n",
    "original_image_np = original_image.get_fdata()\n",
    "max_original = np.max(original_image_np)\n",
    "right_shape = original_image_np.shape\n",
    "right_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4429ce6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_cropy_images: 4\n",
      "ready_to_copy: 6\n"
     ]
    }
   ],
   "source": [
    "# getting cf images\n",
    "ready_to_copy = []\n",
    "to_cropy_images = []\n",
    "ready_file_names = []\n",
    "to_cropy_file_names = []\n",
    "for each_path in comp_rever_paths_all:\n",
    "    whole_path = os.path.join(cf_images_path,each_path)\n",
    "    file_generated = [filename for filename in os.listdir(whole_path) if filename.startswith(f\"{original_image_eid}\")]\n",
    "    image_load = nib.load(os.path.join(whole_path, file_generated[0])).get_fdata()\n",
    "    if image_load.shape != right_shape:\n",
    "        to_cropy_images.append(image_load)\n",
    "        to_cropy_file_names.append(f\"{each_path}_{original_image_eid}.nii.gz\")\n",
    "    else:\n",
    "        ready_to_copy.append(image_load)\n",
    "        ready_file_names.append(f\"{each_path}_{original_image_eid}.nii.gz\")\n",
    "print(f\"to_cropy_images: {len(to_cropy_images)}\")\n",
    "print(f\"ready_to_copy: {len(ready_to_copy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5caf16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 100)\n",
      "(150, 150, 100)\n",
      "(150, 150, 100)\n",
      "(150, 150, 100)\n"
     ]
    }
   ],
   "source": [
    "# cropping to same size of original image\n",
    "for idx,each_generated_image in enumerate(to_cropy_images):\n",
    "    generated_shape = each_generated_image.shape\n",
    "    x_initial = int((generated_shape[0] - right_shape[0])/2)\n",
    "    x_fim = x_initial +  right_shape[0]\n",
    "    y_initial = int((generated_shape[1] - right_shape[1])/2)\n",
    "    y_fim = y_initial +  right_shape[1]\n",
    "    z_initial = int((generated_shape[2] - right_shape[2])/2)\n",
    "    z_fim = z_initial +  right_shape[2]\n",
    "    each_generated_image = each_generated_image[x_initial:x_fim,y_initial:y_fim,z_initial:z_fim] \n",
    "    print(each_generated_image.shape)\n",
    "    ready_to_copy.append(each_generated_image)\n",
    "    ready_file_names.append(to_cropy_file_names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f416f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalize\n",
    "for idx,one_image in enumerate(ready_to_copy):\n",
    "    #minv = max_min_original[idx][z]['min']\n",
    "    ready_to_copy[idx][:,:,:]= one_image[:,:,:] * max_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed14a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1859.8780229251133\n",
      "1853.3949414656963\n",
      "1830.978811123874\n",
      "1840.9674442468095\n",
      "1840.9677734375\n",
      "1840.9925724695204\n",
      "1157.9921169545269\n",
      "1656.3800191518385\n",
      "1158.765385886596\n",
      "1639.4615928024286\n"
     ]
    }
   ],
   "source": [
    "for each_image in ready_to_copy:\n",
    "    print(np.max(each_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919a2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, each_image in enumerate(ready_to_copy):\n",
    "    ni_img = nib.Nifti1Image(each_image, original_image.affine, original_image.header)\n",
    "    nib.save(ni_img,os.path.join(output_path,ready_file_names[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694035d7",
   "metadata": {},
   "source": [
    "# Effectiviness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1439eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = '/home/erik.ohara/BrainAge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82f02ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv(pred_path + '/predictions_real_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc76dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.rename(columns={\"Age\": \"Original_Age\", \n",
    "                        \"Prediction\": \"Original_Prediction\", \n",
    "                        \"ABSError\": \"Original_ABSError\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e19a66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf_2_5 = pd.read_csv(pred_path + '/predictions_cf_age_2_5YZ_65.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c741e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf_analysis_2_5 = df_cf_2_5.set_index('EID').join(\n",
    "                                            df_orig[['EID',\n",
    "                                                     'Original_Age',\n",
    "                                                     'Original_Prediction',\n",
    "                                                     'Original_ABSError']].set_index('EID'), \n",
    "                                                on='EID', \n",
    "                                                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08e04f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>ABSError</th>\n",
       "      <th>ABSMEANError</th>\n",
       "      <th>Original_Age</th>\n",
       "      <th>Original_Prediction</th>\n",
       "      <th>Original_ABSError</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1020415</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>69.359840</td>\n",
       "      <td>4.359840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.551643</td>\n",
       "      <td>0.551643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025653</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>64.357056</td>\n",
       "      <td>0.642944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>64.510208</td>\n",
       "      <td>1.489792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026490</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>58.531548</td>\n",
       "      <td>6.468452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.647549</td>\n",
       "      <td>1.647549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027217</th>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>64.799194</td>\n",
       "      <td>0.200806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.800774</td>\n",
       "      <td>0.199226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027582</th>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>57.977489</td>\n",
       "      <td>7.022511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.508553</td>\n",
       "      <td>0.508553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002830</th>\n",
       "      <td>2365</td>\n",
       "      <td>65</td>\n",
       "      <td>57.014378</td>\n",
       "      <td>7.985622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>54.441154</td>\n",
       "      <td>2.441154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003437</th>\n",
       "      <td>2366</td>\n",
       "      <td>65</td>\n",
       "      <td>69.366486</td>\n",
       "      <td>4.366486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.560837</td>\n",
       "      <td>2.560837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004251</th>\n",
       "      <td>2367</td>\n",
       "      <td>65</td>\n",
       "      <td>72.731667</td>\n",
       "      <td>7.731667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>74.707329</td>\n",
       "      <td>0.292671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007875</th>\n",
       "      <td>2368</td>\n",
       "      <td>65</td>\n",
       "      <td>65.384827</td>\n",
       "      <td>0.384827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>65.767685</td>\n",
       "      <td>0.232315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023202</th>\n",
       "      <td>2369</td>\n",
       "      <td>65</td>\n",
       "      <td>73.333626</td>\n",
       "      <td>8.333626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.135048</td>\n",
       "      <td>0.135048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2370 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Age  Prediction  ABSError  ABSMEANError  Original_Age  \\\n",
       "EID                                                                          \n",
       "1020415           0   65   69.359840  4.359840           0.0          70.0   \n",
       "1025653           1   65   64.357056  0.642944           0.0          66.0   \n",
       "1026490           2   65   58.531548  6.468452           0.0          56.0   \n",
       "1027217           3   65   64.799194  0.200806           0.0          65.0   \n",
       "1027582           4   65   57.977489  7.022511           0.0          55.0   \n",
       "...             ...  ...         ...       ...           ...           ...   \n",
       "6002830        2365   65   57.014378  7.985622           0.0          52.0   \n",
       "6003437        2366   65   69.366486  4.366486           0.0          67.0   \n",
       "6004251        2367   65   72.731667  7.731667           0.0          75.0   \n",
       "6007875        2368   65   65.384827  0.384827           0.0          66.0   \n",
       "6023202        2369   65   73.333626  8.333626           0.0          74.0   \n",
       "\n",
       "         Original_Prediction  Original_ABSError  \n",
       "EID                                              \n",
       "1020415            70.551643           0.551643  \n",
       "1025653            64.510208           1.489792  \n",
       "1026490            57.647549           1.647549  \n",
       "1027217            64.800774           0.199226  \n",
       "1027582            55.508553           0.508553  \n",
       "...                      ...                ...  \n",
       "6002830            54.441154           2.441154  \n",
       "6003437            69.560837           2.560837  \n",
       "6004251            74.707329           0.292671  \n",
       "6007875            65.767685           0.232315  \n",
       "6023202            74.135048           0.135048  \n",
       "\n",
       "[2370 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cf_analysis_2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0136fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EID de mais novo: 1069990\n",
      "Unnamed: 0             28.000000\n",
      "Age                    65.000000\n",
      "Prediction             66.231369\n",
      "ABSError                1.231369\n",
      "ABSMEANError            0.000000\n",
      "Original_Age           59.000000\n",
      "Original_Prediction    63.063900\n",
      "Original_ABSError       4.063900\n",
      "Name: 1069990, dtype: float64\n",
      "\n",
      "EID de mais novo: 1070244\n",
      "Unnamed: 0             29.000000\n",
      "Age                    65.000000\n",
      "Prediction             63.914474\n",
      "ABSError                1.085526\n",
      "ABSMEANError            0.000000\n",
      "Original_Age           58.000000\n",
      "Original_Prediction    60.790791\n",
      "Original_ABSError       2.790791\n",
      "Name: 1070244, dtype: float64\n",
      "\n",
      "EID de mais velho: 1128143\n",
      "Unnamed: 0             49.000000\n",
      "Age                    65.000000\n",
      "Prediction             66.473579\n",
      "ABSError                1.473579\n",
      "ABSMEANError            0.000000\n",
      "Original_Age           75.000000\n",
      "Original_Prediction    69.674744\n",
      "Original_ABSError       5.325256\n",
      "Name: 1128143, dtype: float64\n",
      "\n",
      "EID de mais novo: 1455398\n",
      "Unnamed: 0             211.000000\n",
      "Age                     65.000000\n",
      "Prediction              63.989433\n",
      "ABSError                 1.010567\n",
      "ABSMEANError             0.000000\n",
      "Original_Age            59.000000\n",
      "Original_Prediction     60.854340\n",
      "Original_ABSError        1.854340\n",
      "Name: 1455398, dtype: float64\n",
      "\n",
      "EID de mais novo: 1473758\n",
      "Unnamed: 0             217.000000\n",
      "Age                     65.000000\n",
      "Prediction              64.709366\n",
      "ABSError                 0.290634\n",
      "ABSMEANError             0.000000\n",
      "Original_Age            52.000000\n",
      "Original_Prediction     58.195492\n",
      "Original_ABSError        6.195492\n",
      "Name: 1473758, dtype: float64\n",
      "\n",
      "EID de mais novo: 1571589\n",
      "Unnamed: 0             260.000000\n",
      "Age                     65.000000\n",
      "Prediction              65.110550\n",
      "ABSError                 0.110550\n",
      "ABSMEANError             0.000000\n",
      "Original_Age            52.000000\n",
      "Original_Prediction     60.519596\n",
      "Original_ABSError        8.519596\n",
      "Name: 1571589, dtype: float64\n",
      "\n",
      "EID de mais velho: 1831865\n",
      "Unnamed: 0             384.000000\n",
      "Age                     65.000000\n",
      "Prediction              66.136642\n",
      "ABSError                 1.136642\n",
      "ABSMEANError             0.000000\n",
      "Original_Age            75.000000\n",
      "Original_Prediction     69.717049\n",
      "Original_ABSError        5.282951\n",
      "Name: 1831865, dtype: float64\n",
      "\n",
      "EID de mais velho: 2149396\n",
      "Unnamed: 0             532.000000\n",
      "Age                     65.000000\n",
      "Prediction              64.395576\n",
      "ABSError                 0.604424\n",
      "ABSMEANError             0.000000\n",
      "Original_Age            72.000000\n",
      "Original_Prediction     67.814926\n",
      "Original_ABSError        4.185074\n",
      "Name: 2149396, dtype: float64\n",
      "\n",
      "EID de mais novo: 2959040\n",
      "Unnamed: 0             901.000000\n",
      "Age                     65.000000\n",
      "Prediction              65.084839\n",
      "ABSError                 0.084839\n",
      "ABSMEANError             0.000000\n",
      "Original_Age            54.000000\n",
      "Original_Prediction     61.696136\n",
      "Original_ABSError        7.696136\n",
      "Name: 2959040, dtype: float64\n",
      "\n",
      "EID de mais velho: 3467967\n",
      "Unnamed: 0             1136.000000\n",
      "Age                      65.000000\n",
      "Prediction               65.030502\n",
      "ABSError                  0.030502\n",
      "ABSMEANError              0.000000\n",
      "Original_Age             74.000000\n",
      "Original_Prediction      69.399055\n",
      "Original_ABSError         4.600945\n",
      "Name: 3467967, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "achou_maior = False\n",
    "achou_menor = False\n",
    "error_maior = 99999\n",
    "error_menor = 999999\n",
    "for index, row in df_cf_analysis_2_5.iterrows():\n",
    "    if (abs(row['Prediction'] - row['Original_Prediction']) > 3) and (row['ABSError']<2):\n",
    "        if (row['Original_Age'] > row['Age']):\n",
    "            if (row['ABSError'] < error_maior):\n",
    "                achou_maior = True\n",
    "                error_maior = row['ABSError']\n",
    "                print(f\"EID de mais velho: {index}\")\n",
    "                print(row)\n",
    "                print()\n",
    "        elif (row['Original_Age'] < row['Age']):\n",
    "            if (row['ABSError'] < error_menor):\n",
    "                achou_menor = True\n",
    "                error_menor = row['ABSError']\n",
    "                print(f\"EID de mais novo: {index}\")\n",
    "                print(row)\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d77dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eid_younger = 2908349\n",
    "eid_older = 3467967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02122a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age 65\n",
    "axial_path_65 = '2_5Z_65'\n",
    "twofive_path_65 = '2_5YZ_65'\n",
    "pca3D_path_65 = 'PCA3D_15000_new_65'\n",
    "autoencoder_path_65 = 'macaw_AE3D_6000_65'\n",
    "vqvae_path_65 = 'macaw_vqvae8_50nevecs_saving_65'\n",
    "\n",
    "effec_age_paths_all = [axial_path_65,\n",
    "                       twofive_path_65,\n",
    "                       pca3D_path_65,\n",
    "                       autoencoder_path_65,\n",
    "                       vqvae_path_65]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8172a2",
   "metadata": {},
   "source": [
    "## Younger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28717983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting original images\n",
    "original_image_younger = nib.load(os.path.join(original_image_path, str(eid_younger) + \".nii.gz\"))\n",
    "original_image_younger_np = original_image_younger.get_fdata()\n",
    "max_original_younger = np.max(original_image_younger_np)\n",
    "right_shape_younger = original_image_younger_np.shape\n",
    "right_shape_younger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6420dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_cropy_images: 2\n",
      "ready_to_copy: 3\n"
     ]
    }
   ],
   "source": [
    "# getting cf images\n",
    "ready_to_copy = []\n",
    "to_cropy_images = []\n",
    "ready_file_names = []\n",
    "to_cropy_file_names = []\n",
    "for each_path in effec_age_paths_all:\n",
    "    whole_path = os.path.join(cf_images_path,each_path)\n",
    "    file_generated = [filename for filename in os.listdir(whole_path) if filename.startswith(f\"{eid_younger}\")]\n",
    "    image_load = nib.load(os.path.join(whole_path, file_generated[0])).get_fdata()\n",
    "    if image_load.shape != right_shape_younger:\n",
    "        to_cropy_images.append(image_load)\n",
    "        to_cropy_file_names.append(f\"{each_path}_{eid_younger}.nii.gz\")\n",
    "    else:\n",
    "        ready_to_copy.append(image_load)\n",
    "        ready_file_names.append(f\"{each_path}_{eid_younger}.nii.gz\")\n",
    "print(f\"to_cropy_images: {len(to_cropy_images)}\")\n",
    "print(f\"ready_to_copy: {len(ready_to_copy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a70eba36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 100)\n",
      "(150, 150, 100)\n"
     ]
    }
   ],
   "source": [
    "# cropping to same size of original image\n",
    "for idx,each_generated_image in enumerate(to_cropy_images):\n",
    "    generated_shape = each_generated_image.shape\n",
    "    x_initial = int((generated_shape[0] - right_shape_younger[0])/2)\n",
    "    x_fim = x_initial +  right_shape_younger[0]\n",
    "    y_initial = int((generated_shape[1] - right_shape_younger[1])/2)\n",
    "    y_fim = y_initial +  right_shape_younger[1]\n",
    "    z_initial = int((generated_shape[2] - right_shape_younger[2])/2)\n",
    "    z_fim = z_initial +  right_shape_younger[2]\n",
    "    each_generated_image = each_generated_image[x_initial:x_fim,y_initial:y_fim,z_initial:z_fim] \n",
    "    print(each_generated_image.shape)\n",
    "    ready_to_copy.append(each_generated_image)\n",
    "    ready_file_names.append(to_cropy_file_names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9651f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalize\n",
    "for idx,one_image in enumerate(ready_to_copy):\n",
    "    #minv = max_min_original[idx][z]['min']\n",
    "    ready_to_copy[idx][:,:,:] = one_image[:,:,:] * max_original_younger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e64b8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3586.8414125534473\n",
      "3536.9825159875327\n",
      "2742.7438581683964\n",
      "1697.9411083068699\n",
      "1809.1487040028878\n"
     ]
    }
   ],
   "source": [
    "for each_image in ready_to_copy:\n",
    "    print(np.max(each_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e14a5cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, each_image in enumerate(ready_to_copy):\n",
    "    ni_img = nib.Nifti1Image(each_image, original_image_younger.affine, original_image_younger.header)\n",
    "    nib.save(ni_img,os.path.join(output_path,ready_file_names[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f9cc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_younger = []\n",
    "for each_image in ready_to_copy:\n",
    "    diff_younger.append(original_image_younger_np - each_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7974c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, each_image in enumerate(diff_younger):\n",
    "    ni_img = nib.Nifti1Image(each_image, original_image_younger.affine, original_image_younger.header)\n",
    "    nib.save(ni_img,os.path.join(output_path,f\"diff_{ready_file_names[idx]}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187c5ed0",
   "metadata": {},
   "source": [
    "## older"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9d3797c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150, 100)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting original images\n",
    "original_image_older = nib.load(os.path.join(original_image_path, str(eid_older) + \".nii.gz\"))\n",
    "original_image_older_np = original_image_older.get_fdata()\n",
    "max_original_older = np.max(original_image_older_np)\n",
    "right_shape_older = original_image_older_np.shape\n",
    "right_shape_older"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f1e58a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_cropy_images: 2\n",
      "ready_to_copy: 3\n"
     ]
    }
   ],
   "source": [
    "# getting cf images\n",
    "ready_to_copy = []\n",
    "to_cropy_images = []\n",
    "ready_file_names = []\n",
    "to_cropy_file_names = []\n",
    "for each_path in effec_age_paths_all:\n",
    "    whole_path = os.path.join(cf_images_path,each_path)\n",
    "    file_generated = [filename for filename in os.listdir(whole_path) if filename.startswith(f\"{eid_older}\")]\n",
    "    image_load = nib.load(os.path.join(whole_path, file_generated[0])).get_fdata()\n",
    "    if image_load.shape != right_shape_older:\n",
    "        to_cropy_images.append(image_load)\n",
    "        to_cropy_file_names.append(f\"{each_path}_{eid_older}.nii.gz\")\n",
    "    else:\n",
    "        ready_to_copy.append(image_load)\n",
    "        ready_file_names.append(f\"{each_path}_{eid_older}.nii.gz\")\n",
    "print(f\"to_cropy_images: {len(to_cropy_images)}\")\n",
    "print(f\"ready_to_copy: {len(ready_to_copy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0353d699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 100)\n",
      "(150, 150, 100)\n"
     ]
    }
   ],
   "source": [
    "# cropping to same size of original image\n",
    "for idx,each_generated_image in enumerate(to_cropy_images):\n",
    "    generated_shape = each_generated_image.shape\n",
    "    x_initial = int((generated_shape[0] - right_shape_older[0])/2)\n",
    "    x_fim = x_initial +  right_shape_older[0]\n",
    "    y_initial = int((generated_shape[1] - right_shape_older[1])/2)\n",
    "    y_fim = y_initial +  right_shape_older[1]\n",
    "    z_initial = int((generated_shape[2] - right_shape_older[2])/2)\n",
    "    z_fim = z_initial +  right_shape_older[2]\n",
    "    each_generated_image = each_generated_image[x_initial:x_fim,y_initial:y_fim,z_initial:z_fim] \n",
    "    print(each_generated_image.shape)\n",
    "    ready_to_copy.append(each_generated_image)\n",
    "    ready_file_names.append(to_cropy_file_names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "043d5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalize\n",
    "for idx,one_image in enumerate(ready_to_copy):\n",
    "    #minv = max_min_original[idx][z]['min']\n",
    "    ready_to_copy[idx][:,:,:] = one_image[:,:,:] * max_original_older"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2837f03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558.8056161672575\n",
      "2584.5609478432743\n",
      "2009.579875253694\n",
      "1368.802102773072\n",
      "1448.1391632009181\n"
     ]
    }
   ],
   "source": [
    "for each_image in ready_to_copy:\n",
    "    print(np.max(each_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59d771cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, each_image in enumerate(ready_to_copy):\n",
    "    ni_img = nib.Nifti1Image(each_image, original_image_older.affine, original_image_older.header)\n",
    "    nib.save(ni_img,os.path.join(output_path,ready_file_names[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84f5062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_older = []\n",
    "for each_image in ready_to_copy:\n",
    "    diff_older.append(original_image_older_np - each_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6db0a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, each_image in enumerate(diff_older):\n",
    "    ni_img = nib.Nifti1Image(each_image, original_image_older.affine, original_image_older.header)\n",
    "    nib.save(ni_img,os.path.join(output_path,f\"diff_{ready_file_names[idx]}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db845fb0",
   "metadata": {},
   "source": [
    "## Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2fe20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_eid = 3788604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1dde498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all females\n",
    "axial_path_sex = '2_5Z_sex_0'\n",
    "twofive_path_sex = '2_5YZ_sex_0'\n",
    "pca3D_path_sex = 'PCA3D_15000_new_sex_females'\n",
    "autoencoder_sex = 'macaw_AE3D_6000_sex_0'\n",
    "vqvae_path_sex = 'macaw_vqvae8_50nevecs_saving_sex_0'\n",
    "\n",
    "effec_sex_paths_all = [axial_path_sex,\n",
    "                       twofive_path_sex,\n",
    "                       pca3D_path_sex,\n",
    "                       autoencoder_sex,\n",
    "                       vqvae_path_sex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c4ded8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150, 100)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting original images\n",
    "original_image_male = nib.load(os.path.join(original_image_path, str(male_eid) + \".nii.gz\"))\n",
    "original_image_male_np = original_image_male.get_fdata()\n",
    "max_original_male = np.max(original_image_male_np)\n",
    "right_shape_male = original_image_male_np.shape\n",
    "right_shape_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "edf7e733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_cropy_images: 2\n",
      "ready_to_copy: 3\n"
     ]
    }
   ],
   "source": [
    "# getting cf images\n",
    "ready_to_copy = []\n",
    "to_cropy_images = []\n",
    "ready_file_names = []\n",
    "to_cropy_file_names = []\n",
    "for each_path in effec_sex_paths_all:\n",
    "    whole_path = os.path.join(cf_images_path,each_path)\n",
    "    file_generated = [filename for filename in os.listdir(whole_path) if filename.startswith(f\"{male_eid}\")]\n",
    "    image_load = nib.load(os.path.join(whole_path, file_generated[0])).get_fdata()\n",
    "    if image_load.shape != right_shape_male:\n",
    "        to_cropy_images.append(image_load)\n",
    "        to_cropy_file_names.append(f\"{each_path}_{male_eid}.nii.gz\")\n",
    "    else:\n",
    "        ready_to_copy.append(image_load)\n",
    "        ready_file_names.append(f\"{each_path}_{male_eid}.nii.gz\")\n",
    "print(f\"to_cropy_images: {len(to_cropy_images)}\")\n",
    "print(f\"ready_to_copy: {len(ready_to_copy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "89f47887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 100)\n",
      "(150, 150, 100)\n"
     ]
    }
   ],
   "source": [
    "# cropping to same size of original image\n",
    "for idx,each_generated_image in enumerate(to_cropy_images):\n",
    "    generated_shape = each_generated_image.shape\n",
    "    x_initial = int((generated_shape[0] - right_shape_male[0])/2)\n",
    "    x_fim = x_initial +  right_shape_male[0]\n",
    "    y_initial = int((generated_shape[1] - right_shape_male[1])/2)\n",
    "    y_fim = y_initial +  right_shape_male[1]\n",
    "    z_initial = int((generated_shape[2] - right_shape_male[2])/2)\n",
    "    z_fim = z_initial +  right_shape_male[2]\n",
    "    each_generated_image = each_generated_image[x_initial:x_fim,y_initial:y_fim,z_initial:z_fim] \n",
    "    print(each_generated_image.shape)\n",
    "    ready_to_copy.append(each_generated_image)\n",
    "    ready_file_names.append(to_cropy_file_names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "63de174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalize\n",
    "for idx,one_image in enumerate(ready_to_copy):\n",
    "    #minv = max_min_original[idx][z]['min']\n",
    "    ready_to_copy[idx][:,:,:] = one_image[:,:,:] * max_original_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3c955468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2079.210764336167\n",
      "2106.45360993105\n",
      "1872.7803535707062\n",
      "1338.7623331113718\n",
      "1310.067815844377\n"
     ]
    }
   ],
   "source": [
    "for each_image in ready_to_copy:\n",
    "    print(np.max(each_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7193ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, each_image in enumerate(ready_to_copy):\n",
    "    ni_img = nib.Nifti1Image(each_image, original_image_male.affine, original_image_male.header)\n",
    "    nib.save(ni_img,os.path.join(output_path,ready_file_names[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16aa3f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_male = []\n",
    "for each_image in ready_to_copy:\n",
    "    diff_male.append(original_image_male_np - each_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "edf46370",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, each_image in enumerate(diff_male):\n",
    "    ni_img = nib.Nifti1Image(each_image, original_image_male.affine, original_image_male.header)\n",
    "    nib.save(ni_img,os.path.join(output_path,f\"diff_{ready_file_names[idx]}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac19281f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
